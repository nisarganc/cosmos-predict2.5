checkpoint:
  broadcast_via_filesystem: 'False'
  dcp_allow_mismatched_size: 'False'
  dcp_async_mode_enabled: 'False'
  jit:
    device: cuda
    dtype: bfloat16
    enabled: 'False'
    input_shape: null
    strict: 'True'
  keys_not_to_resume: []
  load_ema_to_reg: 'False'
  load_from_object_store:
    bucket: bucket
    credentials: credentials/s3_checkpoint.secret
    enabled: 'True'
  load_training_state: 'False'
  only_load_scheduler_state: 'False'
  save_iter: '500'
  save_to_object_store:
    bucket: bucket
    credentials: credentials/s3_checkpoint.secret
    enabled: 'True'
  strict_resume: 'True'
  verbose: 'True'
dataloader_train:
  dataloaders:
    alpamayo:
      dataloader:
        dataset:
          embedding_type: null
      ratio: '0'
    alpamayo_1cap:
      dataloader:
        dataset:
          embedding_type: null
      ratio: '1'
    alpamayo_allcaps:
      dataloader:
        dataset:
          embedding_type: null
      ratio: '1'
    image_data:
      dataloader:
        batch_size: '12'
        cache_size: '8'
        concat_size: '1'
        dataset:
          augmentor_name: image_basic_augmentor_without_embeddings
          caption_type: qwen2p5_7b_v4
          dataset_resolution_type: gt720p
          embedding_type: null
          resolution: 720p
        num_workers: '6'
        use_cache: 'False'
      ratio: '0'
    mads:
      dataloader:
        dataset:
          embedding_type: null
      ratio: '0'
    video_data:
      dataloader:
        batch_size: '1'
        cache_size: '16'
        concat_size: '1'
        dataset:
          augmentor_name: video_basic_augmentor_v2
          caption_type: t2w_qwen2p5_7b
          dataset_resolution_type: all
          embedding_type: null
          max_fps_thres: '60'
          min_fps_thres: '10'
          num_video_frames: '93'
          resolution: 720p
          use_native_fps: 'True'
          video_decoder_name: video_naive_bytes
        use_cache: 'False'
      ratio: '0'
dataloader_val:
  dataloaders:
    image_data:
      dataloader:
        batch_size: '2'
        cache_replay_name: image_dataloader
        cache_size: '32'
        concat_size: '1'
        dataset:
          len_t5: '512'
          resolution: '512'
          t5_dim: '1024'
        num_workers: '8'
        pin_memory: 'True'
        shuffle: 'False'
        use_cache: 'False'
        webdataset: 'False'
      ratio: '1'
    video_data:
      dataloader:
        batch_size: '1'
        cache_replay_name: video_dataloader
        cache_size: '32'
        concat_size: '1'
        dataset:
          len_t5: '512'
          num_video_frames: '136'
          resolution: '512'
          t5_dim: '1024'
        num_workers: '8'
        pin_memory: 'True'
        shuffle: 'False'
        use_cache: 'False'
        webdataset: 'False'
      ratio: '1'
defaults:
- _self_
- data_train: mock
- data_val: mock
- optimizer: fusedadamw
- scheduler: lambdalinear
- model: ddp
- callbacks: basic
- net: null
- conditioner: video_prediction_conditioner
- ema: power
- tokenizer: cosmos_tokenizer_causal_cv8x8x8_c16_res720_t121_it121_v1_0
- checkpoint: s3
- ckpt_type: dummy
- experiment: null
job:
  group: cosmos2_mv
  name: buttercup_predict2p5_2b_7views_res720p_fps30_t8_from48kfps30mv_condprobs0442_joint_alpamayo1capnoviewprefix_allcapsviewprefix_29frames_nofps
  project: cosmos_predict2_multiview
  wandb_mode: online
model:
  _recursive_: 'False'
  config:
    condition_locations:
    - first_random_n
    conditional_frame_timestep: -1.0
    conditional_frames_probs:
      0: 0.4
      1: 0.4
      2: 0.2
    conditioner:
      fps:
        dropout_rate: '0.0'
        dtype: null
        input_key: fps
        output_key: fps
      padding_mask:
        dropout_rate: '0.0'
        dtype: null
        input_key: padding_mask
        output_key: padding_mask
      ref_cam_view_idx_sample_position:
        dropout_rate: '0.0'
        dtype: null
        input_key: ref_cam_view_idx_sample_position
        output_key: ref_cam_view_idx_sample_position
      text:
        credential_path: credentials/s3_training.secret
        dropout_rate: '0.2'
        empty_string_embeddings_path: s3://bucket/predict2_assets/reason1_empty_string_embeddings.pt
        input_key:
        - t5_text_embeddings
        use_empty_string: 'False'
      use_video_condition:
        dropout_rate: '0.0'
        input_key: fps
        output_key: use_video_condition
      view_indices_B_T:
        dropout_rate: '0.0'
        dtype: null
        input_key: latent_view_indices_B_T
        output_key: view_indices_B_T
    conditioning_strategy: frame_replace
    denoise_replace_gt_frames: true
    ema:
      enabled: false
      iteration_shift: 0
      rate: 0.1
    fsdp_shard_size: 1
    high_sigma_ratio: 0.05
    high_sigma_timesteps_max: 1000
    high_sigma_timesteps_min: 980
    init_lora_weights: true
    input_caption_key: ai_caption
    input_data_key: video
    input_image_key: images
    lora_alpha: 32
    lora_rank: 32
    lora_target_modules: q_proj,k_proj,v_proj,output_proj,mlp.layer1,mlp.layer2
    max_num_conditional_frames: 2
    max_num_conditional_frames_per_view: 2
    min_num_conditional_frames: 0
    min_num_conditional_frames_per_view: 0
    net:
      adaln_lora_dim: '256'
      atten_backend: minimal_a2a
      concat_padding_mask: 'True'
      concat_view_embedding: 'True'
      crossattn_emb_channels: '1024'
      crossattn_proj_in_channels: '100352'
      extra_per_block_abs_pos_emb: 'False'
      in_channels: '16'
      layer_mask: null
      max_frames: '128'
      max_img_h: '240'
      max_img_w: '240'
      mlp_ratio: '4.0'
      model_channels: '2048'
      n_cameras_emb: '7'
      num_blocks: '28'
      num_heads: '16'
      out_channels: '16'
      patch_spatial: '2'
      patch_temporal: '1'
      pos_emb_cls: rope3d
      pos_emb_interpolation: crop
      pos_emb_learnable: 'True'
      rope_enable_fps_modulation: 'False'
      rope_h_extrapolation_ratio: '3.0'
      rope_t_extrapolation_ratio: '0.3333333333333333'
      rope_w_extrapolation_ratio: '3.0'
      sac_config:
        every_n_blocks: 1
        mode: predict2_2b_720
      state_t: '8'
      timestep_scale: '0.001'
      use_adaln_lora: 'True'
      use_crossattn_projection: 'True'
      use_wan_fp32_strategy: 'True'
      view_condition_dim: '7'
    online_text_embeddings_as_dict: false
    precision: bfloat16
    resolution: 720p
    shift: 5
    state_ch: 16
    state_t: 8
    text_encoder_class: reason1p1_7B
    text_encoder_config:
      ckpt_path: s3://bucket/cosmos_reasoning1/sft_exp700/sft_exp721-1_qwen7b_tl_721_5vs5_s3_balanced_n32_resume_16k/checkpoints/iter_000016000/model/
      compute_online: true
      embedding_concat_strategy: full_concat
      model_config:
        model_config:
          activation_checkpoint:
            mode: selective
            models: vlm
            selective_ac_option: op
          add_answer_tag: 'True'
          add_cross_attention: 'False'
          add_image_start_end_tag: 'False'
          add_tile_tag: 'False'
          architectures:
          - Qwen2_5_VLForConditionalGeneration
          attention_dropout: '0.0'
          attn_implementation: flash_attention_2
          attn_implementation_autoset: 'True'
          aux_loss_coeff: '0.0'
          bad_words_ids: null
          begin_suppress_tokens: null
          bos_token_id: '151643'
          cache_dir: null
          checkpoint:
            async_mode: disabled
            create_seed_checkpoint: false
            enable_checkpoint: false
            export_dtype: float32
            folder: checkpoint
            interval: 500
            interval_type: steps
            model_weights_only: false
          chunk_size_feed_forward: '0'
          ckpt_dir: null
          ckpt_path: null
          comm:
            init_timeout_seconds: 300
            trace_buf_size: 20000
            train_timeout_seconds: 100
          cp_size: null
          cross_attention_hidden_size: null
          decoder_start_token_id: null
          deterministic: 'False'
          diversity_penalty: '0.0'
          do_sample: 'False'
          early_stopping: 'False'
          encoder_no_repeat_ngram_size: '0'
          eos_token_id: '151645'
          ep_size: null
          experimental:
            enable_async_tensor_parallel: false
            enable_compiled_autograd: false
            pipeline_parallel_degree: 1
          exponential_decay_length_penalty: null
          finetuning_task: null
          float8:
            enable_float8_linear: false
          forced_bos_token_id: null
          forced_eos_token_id: null
          freeze_llm: 'False'
          freeze_mm_projector: 'False'
          freeze_vision_encoder: 'False'
          fsdp_enabled: 'False'
          hidden_act: silu
          hidden_size: '3584'
          id2label:
            0: LABEL_0
            1: LABEL_1
          image_token_id: '151655'
          initializer_range: '0.02'
          intermediate_size: '18944'
          is_decoder: 'False'
          is_encoder_decoder: 'False'
          label2id:
            LABEL_0: '0'
            LABEL_1: '1'
          length_penalty: '1.0'
          loss_per_token: 'True'
          max_batch_size: '1'
          max_length: '20'
          max_position_embeddings: '128000'
          max_seq_len: '128000'
          max_window_layers: '28'
          min_length: '0'
          mm_projector: null
          model_type: qwen2_5_vl
          name_or_path: Qwen/Qwen2.5-VL-7B-Instruct
          no_repeat_ngram_size: '0'
          num_attention_heads: '28'
          num_beam_groups: '1'
          num_beams: '1'
          num_hidden_layers: '28'
          num_key_value_heads: '4'
          num_return_sequences: '1'
          num_tiles: '1'
          optimizer:
            early_step_in_backward: false
            end_lr: 2.5e-05
            fused: false
            init_lr: 1.0e-05
            lr: 0.0003
            lr_multiplier_llm: 1.0
            lr_multiplier_mm_projector: 1.0
            lr_multiplier_vision_encoder: 0.1
            name: AdamW
          output_attentions: 'False'
          output_hidden_states: 'True'
          output_scores: 'False'
          pad_token_id: null
          precision: bfloat16
          prefix: null
          prepend_padding: 'False'
          problem_type: null
          pruned_heads: _Nothing.NOTHING
          remove_invalid_values: 'False'
          repetition_penalty: '1.0'
          return_dict: 'True'
          return_dict_in_generate: 'False'
          rms_norm_eps: 1e-06
          rope_scaling:
            mrope_section:
            - '16'
            - '24'
            - '24'
            rope_type: default
          rope_theta: '1000000.0'
          s3_credential_path: credentials/pbss_dir.secret
          seed: '0'
          sep_token_id: null
          sliding_window: '32768'
          suppress_tokens: null
          task_specific_params: null
          temperature: '1.0'
          tf_legacy_loss: 'False'
          tie_encoder_decoder: 'False'
          tie_word_embeddings: 'False'
          tile_tag_type: space_separated
          tokenizer_class: null
          tokenizer_type: Qwen/Qwen2.5-VL-7B-Instruct
          top_k: '50'
          top_p: '1.0'
          torch_dtype: bfloat16
          torchscript: 'False'
          training:
            compile: false
            context_parallel_degree: 1
            data_parallel_replicate_degree: 1
            data_parallel_shard_degree: -1
            disable_loss_parallel: false
            enable_cpu_offload: false
            fsdp_reshard_after_forward: default
            mixed_precision_param: bfloat16
            mixed_precision_reduce: float32
            steps: 400000
            tensor_parallel_degree: 1
            use_cosine_decay: false
            use_linear_decay: true
            warmup_steps: 1000
          training_seq_len: '4096'
          transformers_version: 4.51.0.dev0
          typical_p: '1.0'
          use_bfloat16: 'False'
          use_cache: 'False'
          use_fsdp2: 'True'
          use_return_dict: 'True'
          use_rope_from_torchtitan: 'False'
          use_sliding_window: 'False'
          video_token_id: '151656'
          vision_config:
            add_cross_attention: 'False'
            architectures: null
            attn_implementation: flash_attention_2
            attn_implementation_autoset: 'True'
            bad_words_ids: null
            begin_suppress_tokens: null
            bos_token_id: null
            chunk_size_feed_forward: '0'
            cross_attention_hidden_size: null
            decoder_start_token_id: null
            depth: '32'
            diversity_penalty: '0.0'
            do_sample: 'False'
            early_stopping: 'False'
            embed_dim: null
            encoder_no_repeat_ngram_size: '0'
            eos_token_id: null
            exponential_decay_length_penalty: null
            finetuning_task: null
            forced_bos_token_id: null
            forced_eos_token_id: null
            fullatt_block_indexes:
            - '7'
            - '15'
            - '23'
            - '31'
            hidden_act: silu
            hidden_size: '1280'
            id2label:
              0: LABEL_0
              1: LABEL_1
            in_channels: '3'
            in_chans: '3'
            intermediate_size: '3420'
            is_decoder: 'False'
            is_encoder_decoder: 'False'
            label2id:
              LABEL_0: '0'
              LABEL_1: '1'
            length_penalty: '1.0'
            max_length: '20'
            min_length: '0'
            mlp_ratio: null
            model_type: qwen2_5_vl
            name_or_path: ''
            no_repeat_ngram_size: '0'
            num_beam_groups: '1'
            num_beams: '1'
            num_heads: '16'
            num_return_sequences: '1'
            out_hidden_size: '3584'
            output_attentions: 'False'
            output_hidden_states: 'False'
            output_scores: 'False'
            pad_token_id: null
            patch_size: '14'
            prefix: null
            problem_type: null
            pruned_heads: _Nothing.NOTHING
            remove_invalid_values: 'False'
            repetition_penalty: '1.0'
            return_dict: 'True'
            return_dict_in_generate: 'False'
            sep_token_id: null
            spatial_merge_size: '2'
            spatial_patch_size: '14'
            suppress_tokens: null
            task_specific_params: null
            temperature: '1.0'
            temporal_patch_size: '2'
            tf_legacy_loss: 'False'
            tie_encoder_decoder: 'False'
            tie_word_embeddings: 'True'
            tokenizer_class: null
            tokens_per_second: '2'
            top_k: '50'
            top_p: '1.0'
            torch_dtype: bfloat16
            torchscript: 'False'
            typical_p: '1.0'
            use_bfloat16: 'False'
            window_size: '112'
          vision_encoder: openai/clip-vit-base-patch32
          vision_encoder_config:
            depth_init: true
            dim: 1024
            ffn_dim_multiplier: null
            head_dim: null
            hidden_act: null
            hidden_dim: 4096
            image_size: 1024
            image_token_id: null
            multiple_of: null
            n_heads: 16
            n_kv_heads: null
            n_layers: 24
            norm_eps: 1.0e-05
            norm_type: rmsnorm
            num_channels: 3
            patch_size: 16
            proj_bias: null
            qkv_bias: null
            rope_theta: 10000.0
            use_cache: false
            use_rope_from_torchtitan: false
          vision_encoder_in_channels: '3'
          vision_end_token_id: '151653'
          vision_start_token_id: '151652'
          vision_token_id: '151654'
          vocab_size: '152064'
          z_loss_coeff: '0.0'
        tokenizer:
          cache_dir: null
          tokenizer_type: Qwen/Qwen2.5-VL-7B-Instruct
      n_layers_per_group: 5
      s3_credential_path: credentials/s3_checkpoint.secret
    tokenizer:
      chunk_duration: '81'
      compile_encode: 'False'
      load_mean_std: 'False'
      name: wan2pt1_tokenizer
      temporal_window: '16'
    train_sample_views_range: null
    train_time_distribution: logitnormal
    train_time_weight: reweighting
    use_dynamic_shift: false
    use_high_sigma_strategy: false
    use_kerras_sigma_at_inference: false
    use_lora: false
    use_torch_compile: false
    view_condition_dropout_max: 0
model_parallel:
  _cpu_offloading_context: null
  async_tensor_model_parallel_allreduce: false
  autocast_dtype: torch.float32
  barrier_with_L1_time: true
  batch_p2p_comm: true
  batch_p2p_sync: true
  bf16: false
  context_parallel_size: 8
  cpu_offloading: false
  cpu_offloading_activations: true
  cpu_offloading_num_layers: 0
  cpu_offloading_weights: true
  cross_entropy_fusion_impl: native
  cross_entropy_loss_fusion: false
  deallocate_pipeline_outputs: false
  defer_embedding_wgrad_compute: false
  deterministic_mode: false
  enable_autocast: false
  expert_model_parallel_size: 1
  expert_tensor_parallel_size: 1
  finalize_model_grads_func: null
  fp16: false
  grad_scale_func: null
  grad_sync_func: null
  gradient_accumulation_fusion: false
  hierarchical_context_parallel_sizes: null
  microbatch_group_size_per_vp_stage: 1
  moe_extended_tp: false
  no_sync_func: null
  num_microbatches_with_partial_activation_checkpoints: null
  overlap_p2p_comm: false
  overlap_p2p_comm_warmup_flush: false
  param_sync_func: null
  params_dtype: torch.float32
  perform_initialization: true
  pipeline_dtype: null
  pipeline_model_parallel_comm_backend: null
  pipeline_model_parallel_size: 1
  pipeline_model_parallel_split_rank: null
  sequence_parallel: false
  tensor_model_parallel_size: 1
  timers: null
  tp_comm_atomic_ag: false
  tp_comm_atomic_rs: false
  tp_comm_bootstrap_backend: nccl
  tp_comm_bulk_dgrad: true
  tp_comm_bulk_wgrad: true
  tp_comm_overlap: false
  tp_comm_overlap_ag: true
  tp_comm_overlap_disable_fc1: false
  tp_comm_overlap_disable_qkv: false
  tp_comm_overlap_rs: true
  tp_comm_overlap_rs_dgrad: false
  tp_comm_split_ag: true
  tp_comm_split_rs: true
  use_cpu_initialization: false
  use_ring_exchange_p2p: false
  use_te_rng_tracker: false
  variable_seq_lengths: false
  virtual_pipeline_model_parallel_size: null
  wgrad_deferral_limit: 0
optimizer:
  betas:
  - '0.9'
  - '0.999'
  eps: 1e-08
  fused: 'True'
  lr: 3e-05
  model: null
  optim_type: adamw
  weight_decay: '0.001'
scheduler:
  cycle_lengths:
  - '400000'
  f_max:
  - '0.99'
  f_min:
  - '0.4'
  f_start:
  - 1e-06
  verbosity_interval: '0'
  warm_up_steps:
  - '100'
trainer:
  callbacks:
    compile_tokenizer:
      compile_after_iterations: '4'
      dynamic: 'False'
      enabled: 'False'
    dataloader_speed:
      every_n: '200'
      save_s3: 'True'
      step_size: '1'
    device_monitor:
      every_n: '200'
      log_memory_detail: 'True'
      save_s3: 'True'
      step_size: '1'
      upload_every_n_mul: '10'
    every_n_sample_ema:
      control_weights:
      - '1.0'
      ctrl_hint_keys: null
      dataset_name: null
      do_x0_prediction: 'False'
      every_n: '2000'
      fix_batch_fp: null
      fps: '30'
      guidance:
      - '0'
      - '3'
      - '7'
      is_ema: 'True'
      is_sample: null
      n_sample_to_save: '128'
      n_sigmas_for_x0_prediction: '4'
      n_view_embed: null
      n_viz_sample: '3'
      n_x0_level: null
      num_sampling_step: '35'
      prompt_type: t5_xxl
      sample_n_views: '7'
      save_s3: 'True'
      show_all_frames: null
      step_size: '1'
      use_negative_prompt: 'False'
    every_n_sample_reg:
      control_weights:
      - '1.0'
      ctrl_hint_keys: null
      dataset_name: null
      do_x0_prediction: 'False'
      every_n: '2000'
      fix_batch_fp: null
      fps: '30'
      guidance:
      - '0'
      - '3'
      - '7'
      is_ema: 'False'
      is_sample: null
      n_sample_to_save: '128'
      n_sigmas_for_x0_prediction: '4'
      n_view_embed: null
      n_viz_sample: '3'
      n_x0_level: null
      num_sampling_step: '35'
      prompt_type: t5_xxl
      sample_n_views: '7'
      save_s3: 'True'
      show_all_frames: null
      step_size: '1'
      use_negative_prompt: 'False'
    grad_clip:
      clip_norm: '0.1'
      force_finite: 'True'
    heart_beat:
      every_n: '10'
      save_s3: 'True'
      step_size: '1'
      update_interval_in_minute: '20'
    iter_speed:
      every_n: '100'
      hit_thres: '50'
      save_s3: 'True'
      save_s3_every_log_n: '10'
    low_prec:
      config: null
      trainer: null
      update_iter: '1'
    manual_gc:
      every_n: '200'
      warm_up: '5'
    wandb:
      logging_iter_multipler: '1'
      save_logging_iter_multipler: '10'
      save_s3: 'True'
    wandb_10x:
      logging_iter_multipler: '10'
      save_logging_iter_multipler: '1'
      save_s3: 'True'
  cudnn:
    benchmark: 'True'
    deterministic: 'False'
  ddp:
    broadcast_buffers: 'True'
    find_unused_parameters: 'False'
    static_graph: 'True'
  distributed_parallelism: fsdp
  grad_accum_iter: '1'
  grad_scaler_args:
    enabled: 'False'
  logging_iter: '200'
  max_iter: '150000'
  max_val_iter: null
  memory_format: torch.preserve_format
  profiling:
    enable_memory_snapshot: 'False'
    enable_profiling: 'False'
    profile_freq: '1'
    profile_memory: 'False'
    record_shape: 'False'
    save_s3: 'False'
    target_ranks:
    - '0'
    - '1'
    - '2'
    - '3'
    - '4'
    - '5'
    - '6'
    - '7'
    with_modules: 'True'
    with_stack: 'True'
  run_validation: 'False'
  seed: '0'
  straggler_detection:
    analyze_backward: 'True'
    analyze_dataloading: 'True'
    analyze_forward: 'True'
    analyze_optimizer: 'True'
    enabled: 'True'
    max_diff: '1.5'
    profile_freq: '1'
    raise_error: 'True'
    report_freq: '100'
  timeout_period: '999999999'
  validation_iter: '100'
upload_reproducible_setup: 'True'
